اصطلاحات استاندارد زیر، نحوه درک ربات از موقعیت خود و محیط اطرافش را تعریف می‌کنند.

آن‌ها را به سه دسته تقسیم می‌کنیم: **چارچوب‌های مختصات (Frames)**، **حسگرها (Sensors)** و **الگوریتم (Algorithm)**.

---

### ۱. چارچوب‌های مختصات (Coordinate Frames)

در رباتیک، ما مکان اشیا را نسبت به یکدیگر می‌سنجیم. این سه مورد، استانداردترین چارچوب‌ها برای ناوبری هستند:

#### **بدنه ربات`base_link` **

- **چیست؟** این چارچوب دقیقاً روی خود ربات چسبیده است. معمولاً مرکز شاسی یا نقطه وسط چرخ‌های متحرک در نظر گرفته می‌شود. هر چیزی که روی ربات نصب شده (سنسورها، دوربین‌ها، بازوها) نسبت به این فریم تعریف می‌شود.
    
- **کاربرد:** وقتی می‌گوییم "سنسور لیزر ۱۰ سانتی‌متر جلوتر نصب شده"، یعنی ۱۰ سانتی‌متر جلوتر از `base_link`.
    
- **نکته:** وقتی ربات حرکت می‌کند، `base_link` هم در فضا حرکت می‌کند.
    

#### **ادومتری - Odometry`odom` **

- **چیست؟** نقطه شروع حرکت ربات است (معمولاً محل روشن شدن). اما یک ویژگی مهم دارد: **پیوستگی**. (درواقع odom یک فریم محلی است که معمولاً **در شروع یا هنگام reset** نزدیک به base قرار داده می‌شود.)
    
- **ویژگی:** یک فریم مختصات محلی است که موقعیت ربات را نسبت به نقطه شروعش نشان می‌دهد. موقعیت ربات در چارچوب `odom` فقط بر اساس سنسورهای داخلی (چرخ‌ها و IMU) محاسبه می‌شود. نکته مهم این است که odom در کوتاه‌مدت دقیق است اما به مرور زمان به خاطر لغزش چرخ‌ها و خطاهای تجمعی، دچار drift می‌شود. این چارچوب پیوسته است (پرش ناگهانی ندارد)، اما به مرور زمان دچار **خطا (Drift)** می‌شود. خطا با حرکت بیشتر افزایش می‌یابد. (در رباتیک، *Drift (دریفت)* یعنی *انحراف تدریجی و ناخواسته از مقدار یا مسیر واقعی*؛ چیزی که یواش‌یواش جمع می‌شود و اگر حواست نباشد، ربات را کاملاً از واقعیت دور می‌کند. لغزش چرخ ناهمواری زمین خطای اندازه‌گیری باعث می‌شود بعد از مدتی جای ربات با واقعیت فرق کند.)
    
- **کاربرد:** برای کنترلر ربات حیاتی است. مثلاً اگر بخواهید ربات "دقیقاً ۱ متر جلو برود"، از این چارچوب استفاده می‌کند چون پرش ناگهانی ندارد. تخمین موقعیت کوتاه‌مدت، کنترل حلقه بسته
    

#### **نقشه جهانی`map` **

- **چیست؟** یک چارچوب ثابت و جهانی است (مثل مختصات GPS یا نقشه ساختمان).
    
- **ویژگی:** بر خلاف `odom`، این چارچوب دچار دریفت نمی‌شود، اما ممکن است موقعیت ربات در آن "پرش" (Jump) داشته باشد. مثلاً ربات ناگهان می‌فهمد که ۲ متر اشتباه کرده و موقعیت خود را در نقشه اصلاح می‌کند.
    
- **کاربرد:** برای ناوبری طولانی‌مدت و رسیدن از نقطه A به نقطه B در ساختمان.
    

> **خلاصه رابطه:**
> 
> - `map` -> `odom` (توسط SLAM محاسبه می‌شود تا خطای دریفت را اصلاح کند).
>     
> - `odom` -> `base_link` (توسط سنسورهای چرخ و IMU محاسبه می‌شود).
>     
- `T_map_base = compose(T_map_odom, T_odom_base)`
---

### ۲. منابع داده (Data Sources)

این‌ها ورودی‌هایی هستند که به ربات کمک می‌کنند بفهمد چقدر حرکت کرده است (تولیدکننده اطلاعات `odom`).

#### **Wheel Odometry (ادومتری چرخ)**

- **نحوه کار:** با استفاده از اینکودرها (Encoder)، تعداد دور چرخ‌ها شمرده می‌شود. با دانستن محیط چرخ، ربات محاسبه می‌کند چقدر جلو رفته است.
    
- **مشکل:** اگر چرخ روی زمین **لغرش (Slip)** کند یا لیز بخورد، ربات فکر می‌کند حرکت کرده اما در واقع ثابت بوده است. این باعث ایجاد خطا می‌شود.
    

#### **IMU (واحد اندازه‌گیری اینرسی)**

- **نحوه کار:** شامل شتاب‌سنج (Accelerometer) و ژیروسکوپ (Gyroscope) است. تغییرات سرعت و چرخش زاویه‌ای را اندازه می‌گیرد.
    
- **کاربرد:** مکمل چرخ‌هاست.IMU کمک می‌کند تخمین جهت‌گیری و نرخ چرخش دقیق‌تر شود و در ترکیب با wheel odom تخمین بهتری بدهیمد. (برای محاسبه**x,y** اگر فقط IMU داشته باشیم، از شتاب باید انتگرال بگیریم و drift زیاد می‌شود؛ بنابراین IMU معمولاً به تنهایی نمی‌تواند “فاصله طی‌شده” را دقیق اصلاح کند. - اصلاح driftِ x,y معمولاً با سنسور محیطی (LiDAR/Camera) و SLAM/Localization انجام می‌شود. IMU (به‌خصوص gyro) بیشتر کمک می‌کند تخمین **چرخش/yaw** بهتر شود.)
    
- **ترکیب داده‌ها (Sensor Fusion):** معمولاً داده‌های _Wheel Odom_ و _IMU_ با فیلتری مثل **کالمن (Kalman Filter)** ترکیب می‌شوند تا موقعیت دقیق `odom` -> `base_link` به دست آید.

ترکیب این سنسورها به خاطر پیوستگی و نرخ بالا و تاخیر کم برای محاسبه `odom->base_link` نسبت به الگوریتم SLAM مناسب‌تر است.

------------------------------------------------

#### **Wheel Odometry**
| جنبه      | توضیحات                             |
| --------- | ----------------------------------- |
| **اصول**  | شمارش چرخش چرخ‌ها (انکودر)          |
| **مزایا** | سریع، ارزان، داده مداوم             |
| **معایب** | خطای تجمعی (لغزش چرخ، سطوح ناهموار) |
| **دقت**   | خوب برای مسافت‌های کوتاه            |
#### **IMU (Inertial Measurement Unit)**
| جنبه        | توضیحات                             |
| ----------- | ----------------------------------- |
| **سنسورها** | شتاب‌سنج + ژیروسکوپ (+ قطب‌نما)     |
| **مزایا**   | نرخ بالا (100-1000Hz)، مستقل از سطح |
| **معایب**   | drift (انحراف) در زمان، نویز        |
| **کاربرد**  | تخمین جهت‌گیری، تشخیص شتاب          |
#### **ترکیب Wheel + IMU**
```plain
موقعیت = Odometry (xy) + IMU (θ - زاویه yaw)
```
- ترکیب داده‌ها: **Sensor Fusion** با فیلتر کالمن یا EKF
    
- جبران نقاط ضعف یکدیگر
---

### ۳. فرآیند کلی: SLAM

**SLAM (Simultaneous Localization and Mapping)**

به معنای **مکان‌یابی و نقشه‌برداری هم‌زمان** است.

- **مشکل مرغ و تخم‌مرغ:** ربات برای اینکه بفهمد کجاست (Localize)، به نقشه نیاز دارد. برای اینکه نقشه بسازد (Map)، باید بداند کجاست. SLAM هر دو مشکل را همزمان حل می‌کند: در حین حرکت، هم نقشه محیط را می‌سازد و هم موقعیت خودش را در آن نقشه پیدا می‌کند.
    
- **راه حل:** SLAM با استفاده از سنسورهای محیطی (مثل **Lidar** یا **دوربین**) و داده‌های ادومتری، همزمان هم نقشه محیط را می‌سازد و هم موقعیت ربات را در آن پیدا می‌کند.
    
- **نتیجه نهایی:** وظیفه SLAM در نهایت این است که اختلاف بین `map` و `odom` را محاسبه کند و رابطه‌ی map -> odom را اصلاح کند و خطای انباشته شده‌ی سنسورهای چرخ را جبران نماید.
-  **الگوریتم‌های کلیدی**:
- EKF-SLAM: فیلتر کالمن توسعه‌یافته
- Graph-based SLAM: بهینه‌سازی گراف (دقت بالاتر)
- Particle Filter: Monte Carlo Localization

    #### **انواع SLAM**
| نوع             | توضیحات                              | مثال                    |
| --------------- | ------------------------------------ | ----------------------- |
| **LiDAR SLAM**  | با لیزر (دقت بالا، محیط‌های ساختاری) | GMapping, Cartographer  |
| **Visual SLAM** | با دوربین (هزینه کم، اطلاعات غنی)    | ORB-SLAM, VINS-Mono     |
| **RGB-D SLAM**  | عمق + رنگ                            | RTAB-Map, Kinect Fusion |
|                 |                                      |                         |

### جمع‌بندی در یک سناریو

تصور کنید یک ربات در خانه دارید:

1. فریم**`base_link`** خودِ ربات است.
    
2. ربات شروع به حرکت می‌کند. با استفاده از **`Wheel Odom`** و **`IMU`** می‌فهمد که "حدوداً" ۲ متر جلو رفته است (این در چارچوب **`odom`** است).
    
3. اما چون فرش لیز بود، ربات واقعاً فقط ۱.۸ متر رفته است (خطای دریفت).
    
4. سنسور لیزر (Lidar) دیوار روبرو را می‌بیند و **`SLAM`** متوجه می‌شود که دیوار هنوز دور است.
    
5. الگوریتم **`SLAM`** می‌گوید: "هی! طبق نقشه‌ی **`map`**، تو عقب‌تر از چیزی هستی که فکر می‌کنی."
    
6. سپس SLAM رابطه‌ی بین `map` و `odom` را اصلاح می‌کند تا موقعیت ربات در نقشه درست شود.
    

نکته کلیدی: odom برای کنترل لحظه‌ای (100Hz) و map برای تصمیم‌گیری استراتژیک (10Hz) استفاده می‌شود. SLAM پل ارتباطی بین این دو است.

نکته بعدی: تفکیک (SLAM و Localization) - اگر نقشه آماده باشد، به جای SLAM از Localization استفاده می‌شود و همچنان map->odom را اصلاح می‌کند.

- ۱. `odom -> base_link` باید **smooth و پیوسته** باشد (برای کنترل)
    
- ۲.`map -> odom` ممکن است **jump** داشته باشد (برای اصلاح drift)
    
- ۳. در نتیجه `map -> base_link` هم “درست” می‌ماند.